{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312e9d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aioodbc\n",
    "import asyncio\n",
    "\n",
    "from config import config\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "async def query_sql_server():\n",
    "    dsn = f'DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={config.SERVER_NAME};DATABASE={config.DATABASE_NAME};UID={config.USERNAME};PWD={config.PASSWORD};trusted_connection=yes'\n",
    "    async with aioodbc.create_pool(dsn=dsn) as pool:\n",
    "        async with pool.acquire() as conn:\n",
    "            async with conn.cursor() as cur:\n",
    "                await cur.execute(\"SELECT * FROM dbo.store_info\")\n",
    "                result = await cur.fetchall()\n",
    "                print(result)\n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "loop.run_until_complete(query_sql_server())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267d3400",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.visual_analyzer import visual_analyzer\n",
    "\n",
    "resp = await visual_analyzer._analyze_single_image(image_path=\"C:\\\\Users\\\\rahul_thatikonda\\\\Desktop\\\\AIStoreAssistant\\\\Inputs\\\\Sample\\\\Store Images\\\\Image_4.jpg\")\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b3cc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.sql_handler import sql_handler\n",
    "\n",
    "resp = sql_handler.query_data('dbo.store_info', filters={\"Store ID\": \"Store1\"})\n",
    "resp.columns = list(Store.model_fields.keys())\n",
    "# resp.to_dict(orient=\"records\")\n",
    "# list(resp.itertuples(index=False, name=None))\n",
    "\n",
    "from database_models import Store\n",
    "\n",
    "Store.model_fields.keys()\n",
    "[Store(**record) for record in resp.to_dict(orient=\"records\")]\n",
    "\n",
    "# from sqlalchemy import create_engine\n",
    "# from config import config\n",
    "\n",
    "# string = f\"mssql+pyodbc://{config.USERNAME}:{config.PASSWORD}@{config.SERVER_NAME}/{config.DATABASE_NAME}?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "\n",
    "# print(string)\n",
    "# engine = create_engine(\n",
    "#                 f\"mssql+pyodbc://{config.USERNAME}:{config.PASSWORD}@{config.SERVER_NAME}/{config.DATABASE_NAME}\"\n",
    "#                 \"?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "#             )\n",
    "# import pandas.io.sql as pdsql\n",
    "\n",
    "# pdsql.read_sql('select * from dbo.store_info', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132eddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.key_frame_detector import keyframeDetection\n",
    "\n",
    "keyframeDetection(source=\"C:\\\\Users\\\\rahul_thatikonda\\\\Desktop\\\\AIStoreAssistant\\\\Inputs\\\\Sample\\\\Store Videos\\\\Video_3.mp4\", Thres=0.4, max_keyframes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77c0944b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field, conint, confloat \n",
    "\n",
    "class Metric(BaseModel):\n",
    "    score: conint(ge=0, le=100) = Field(description=\"Score between 0 and 100\", ge=0, le=100)\n",
    "    details: Optional[str] = Field(description=\"Brief description of the observation\")\n",
    "\n",
    "class StoreEvaluation(BaseModel):\n",
    "    cleanliness: Metric = Field(description=\"How clean and tidy is the store?\")\n",
    "    empty_shelves: Metric = Field(description=\"Are there empty or poorly stocked shelves? (100 = fully stocked, 0 = many empty)\")\n",
    "    queue_length: Optional[Metric] = Field(description=\"Only relevant for checkout situations\")\n",
    "    staff_presence: Metric = Field(description=\"Is staff visible and available? (100 = good staffing, 0 = no staff visible)\")\n",
    "    store_organization: Metric = Field(description=\"How well organized is the store layout?\")\n",
    "    immediate_issues: Optional[List[str]] = Field(default=None, description=\"List of immediate issues, if any\")\n",
    "\n",
    "\n",
    "class ThemeSentiment(BaseModel):\n",
    "    theme: str = Field(description=\"Name of the theme\")\n",
    "    score: confloat(ge=-1, le=1) = Field(description=\"Sentiment score from -1 (very negative) to 1 (very positive)\")\n",
    "    explanation: str = Field(description=\"Brief explanation of the sentiment\")\n",
    "    sample_quotes: List[str] = Field(description=\"Sample quotes from reviews\")\n",
    "\n",
    "class SentimentAnalysis(BaseModel):\n",
    "    themes: List[ThemeSentiment] = Field(description=\"List of theme sentiment analyses\")\n",
    "    overall_sentiment: confloat(ge=-1, le=1) = Field(description=\"Overall sentiment score from -1 to 1\")\n",
    "\n",
    "\n",
    "class QueryResponse(BaseModel):\n",
    "    response: str = Field(description=\"Main answer to the query\")\n",
    "    insights: List[str] = Field(description=\"Key insights derived from analysis\")\n",
    "    recommendations: List[str] = Field(description=\"Actionable recommendations based on findings\")\n",
    "    metrics_referenced: List[str] = Field(description=\"Names or keys of metrics involved in the response\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54599c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.output_parsers import PydanticOutputParser\n",
    "# from pydantic import BaseModel\n",
    "\n",
    "# class StockAnswer(BaseModel):\n",
    "#     symbol: str\n",
    "#     price: float\n",
    "#     rationale: str\n",
    "\n",
    "# parser = PydanticOutputParser(pydantic_object=StockAnswer)\n",
    "# format_instructions = parser.get_format_instructions()\n",
    "\n",
    "# prompt = (\n",
    "#     \"Provide the current stock price.\\n\"\n",
    "#     \"{format}\\n\"\n",
    "#     \"Stock symbol: {symbol}\"\n",
    "# ).format(format=format_instructions, symbol=\"AAPL\")\n",
    "# # Run the Chain\n",
    "# from langchain.llms import OpenAI\n",
    "\n",
    "# llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "# response = llm(prompt)\n",
    "# structured = parser.parse(response)\n",
    "# print(structured.price, structured.rationale)\n",
    "\n",
    "\n",
    "# # Call LLM asynchronously with messages\n",
    "# response = await llm.ainvoke(lc_messages)\n",
    "\n",
    "# # Parse raw text content output into Pydantic model\n",
    "# try:\n",
    "#     parsed_response = parser.parse(response.content)\n",
    "# except Exception as e:\n",
    "#     raise ValueError(f\"Failed to parse response into QueryResponse: {e}\")\n",
    "\n",
    "# return parsed_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55105152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b18f7226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat completion response:<class 'dict'>\n",
      " {'response': \"Okay, let's break down quantum computing in a way that's understandable, even if you don't have a physics background. Here’s a detailed explanation:\\n\\n**Classical Computing vs. Quantum Computing**\\n\\n* **Classical Computers:** These are the computers we use every day. They store information as bits, which are like switches that are either on (1) or off (0). Everything a classical computer does – from browsing the web to running complex simulations – is based on manipulating these bits.\\n* **Quantum Computers:** Quantum computers are fundamentally different. Instead of bits, they use **qubits**. This is the crucial difference.\\n\\n**What is a Qubit?**\\n\\nThink of a regular bit as a light switch – it's either on or off. A qubit is like a dimmer switch. It can be on, off, *or* a combination of both *at the same time*. This is due to a concept called **superposition**. \\n\\n**Superposition:**  This allows a qubit to represent 0, 1, *or* any value in between.  It’s like spinning a coin – until it lands, it’s neither heads nor tails; it’s in a state of being both simultaneously.  The probabilities of it being heads or tails are defined, but until measured, it’s a blend.\\n\\n**Entanglement:** Another key concept. Imagine two of these special qubits. Entanglement means that if you measure the state of one qubit, you instantly know the state of the other, no matter how far apart they are. It's like having two linked coins – if one lands on heads, the other *immediately* lands on tails, even if they’re light-years away.\\n\\n**How do Quantum Computers Work?**\\n\\nInstead of performing calculations step-by-step like classical computers, quantum computers leverage superposition and entanglement to explore *many* possible solutions simultaneously.  They don’t “choose” a single answer like a classical computer; they consider all possibilities at once.  This allows them to potentially solve certain problems much faster.\\n\\n**Algorithms for Quantum Computers:**  Because of the way they operate, quantum computers require entirely new algorithms.  Some notable examples include:\\n\\n* **Shor's Algorithm:** Could break modern encryption (which is why there's a lot of research into post-quantum cryptography).\\n* **Grover's Algorithm:**  Can speed up searching through large databases significantly.\\n* **Quantum Simulation:**  Excellent for simulating molecules and materials, which is useful for drug discovery and materials science.\\n\\n**Current Status & Limitations:**\\n\\n* **Early Stage:** Quantum computing is still in its infancy. Current quantum computers are extremely fragile, require incredibly precise conditions (like near-absolute zero temperatures), and have limited numbers of qubits.\\n* **Error Correction:**  Qubits are prone to errors due to their sensitivity to the environment.  Developing effective error correction techniques is a major challenge.\\n* **Scalability:** Building larger, more powerful quantum computers is extremely difficult.\\n\\n**Potential Applications:**\\n\\n* **Drug Discovery:** Simulating molecules to design new drugs and therapies.\\n* **Materials Science:** Designing new materials with specific properties.\\n* **Financial Modeling:**  Optimizing investment strategies and risk management.\\n* **Cryptography:**  Breaking current encryption and developing new, quantum-resistant methods.\\n* **Artificial Intelligence:**  Potentially accelerating machine learning algorithms.\", 'insights': [\"Quantum computers won't replace classical computers entirely. They're expected to excel at specific, complex problems where classical computers struggle.\", 'The fragility of qubits is a significant hurdle. Maintaining stable quantum states is a core research challenge.', 'While the potential impact is enormous, practical, fault-tolerant quantum computers are still years, possibly decades, away.'], 'recommendations': [\"Stay informed about the latest developments in quantum computing research – it's a rapidly evolving field.\", 'Explore educational resources like MIT’s Quantum Information Science and Engineering (QISE) course or IBM Quantum Experience to learn more.', 'Consider how quantum computing might impact your industry or field of interest.'], 'metrics_referenced': ['Number of qubits (a key measure of a quantum computer’s power)', 'Coherence time (how long a qubit maintains its quantum state – longer is better)', 'Error rate (a measure of how often calculations are corrupted – lower is better)', 'Quantum Volume (a metric combining number of qubits and error rates – a higher number indicates better performance)']}\n",
      "Image analysis result: <class 'dict'>\n",
      " {'cleanliness': {'score': 80, 'details': 'The store appears clean with no visible spills or debris. Floors are tidy.'}, 'empty_shelves': {'score': 75, 'details': 'There are some noticeable gaps in shelves, particularly in the produce area, but overall shelves are adequately stocked.'}, 'queue_length': {'score': 70, 'details': 'There are moderate queues at the two visible checkout lanes.'}, 'staff_presence': {'score': 95, 'details': 'Multiple staff members are visible assisting customers and operating checkouts.'}, 'store_organization': {'score': 95, 'details': 'The store layout is logical and well-organized, with clear signage and product placement.'}, 'immediate_issues': ['Minor spill in aisle 3']}\n",
      "Sentiment analysis JSON: <class 'dict'>\n",
      " {'themes': [{'theme': 'staff', 'score': 0.6, 'explanation': 'Reviews indicate a positive sentiment towards the staff, highlighting their friendliness. However, the wait time detracts slightly from this positive perception.', 'sample_quotes': ['The staff was friendly', 'Amazing experience overall!']}, {'theme': 'wait time', 'score': -0.4, 'explanation': \"Multiple reviews express dissatisfaction with the wait time, describing it as 'terrible' and 'slow'. This is a clear negative sentiment.\", 'sample_quotes': ['The wait time was terrible', 'the checkout process was slow']}, {'theme': 'product quality', 'score': 0.8, 'explanation': \"One review explicitly praises the 'great product quality', demonstrating a strong positive sentiment related to this theme.\", 'sample_quotes': ['Great product quality']}, {'theme': 'checkout', 'score': -0.2, 'explanation': \"A review notes the 'checkout process was slow', indicating a mild negative sentiment regarding the checkout experience.\", 'sample_quotes': ['the checkout process was slow']}], 'overall_sentiment': 0.2}\n"
     ]
    }
   ],
   "source": [
    "from local_openai_client import local_client\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "messages = [\n",
    "        {\"role\": \"user\", \"content\": \"Explain quantum computing in simple terms.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"Provide a detailed analysis and answer. Structure your response as JSON:\n",
    "            {{\n",
    "                \"response\": \"Main answer to the query\",\n",
    "                \"insights\": [\"Key insight 1\", \"Key insight 2\", ...],\n",
    "                \"recommendations\": [\"Recommendation 1\", \"Recommendation 2\", ...],\n",
    "                \"metrics_referenced\": [\"metric1\", \"metric2\", ...]\n",
    "            }}\"\"\"}\n",
    "    ]\n",
    "response = await local_client.chat_completion(messages, temperature=0.5, max_tokens=2000, response_model=QueryResponse)\n",
    "print(f\"Chat completion response:{type(response)}\\n\", response)\n",
    "\n",
    "\n",
    "\n",
    "image_path = \"C:\\\\Users\\\\rahul_thatikonda\\\\Desktop\\\\AIStoreAssistant\\\\Inputs\\\\Images\\\\Store 2\\\\Store2-09-06-2024.png\"\n",
    "prompt = f\"\"\"Analyze this retail store image and provide scores (0-100) for the following metrics:\n",
    "\n",
    "        1. Cleanliness: How clean and tidy is the store?\n",
    "        2. Empty Shelves: Are there empty or poorly stocked shelves? (100 = fully stocked, 0 = many empty)\n",
    "        3. Queue Length: How long are the checkout queues?, this field is only relevant situations like checkout (100 = no queue, 0 = very long queues)\n",
    "        4. Staff Presence: Is staff visible and available? (100 = good staffing, 0 = no staff visible)\n",
    "        5. Store Organization: How well organized is the store layout?\n",
    "        6. Immediate Issues: This is optional field, only provide value if it's relevant to situation ([\"Restock aisle 1\"], [\"\"])\n",
    "\n",
    "        For each metric, provide:\n",
    "        - score (0-100)\n",
    "        - details (brief description - ignore if it's optional or not relevant to situation)\n",
    "\n",
    "        Also identify any issues that need immediate attention (spills, hazards, etc.)\n",
    "\n",
    "        Respond in JSON format:\n",
    "        {{\n",
    "            \"cleanliness\": {{\"score\": 85, \"details\": \"Store is generally clean\"}},\n",
    "            \"empty_shelves\": {{\"score\": 70, \"details\": \"Some gaps in produce section\"}},\n",
    "            \"queue_length\": {{\"score\": 60, \"details\": \"Moderate queues at 2 checkouts\"}},\n",
    "            \"staff_presence\": {{\"score\": 80, \"details\": \"Staff visible in multiple areas\"}},\n",
    "            \"store_organization\": {{\"score\": 90, \"details\": \"Well organized layout\"}},\n",
    "            \"immediate_issues\": [\"Minor spill in aisle 3\"]\n",
    "        }}\"\"\"\n",
    "\n",
    "response = await local_client.analyze_image(image_path, prompt, response_model=StoreEvaluation)\n",
    "print(f\"Image analysis result: {type(response)}\\n\", response)\n",
    "\n",
    "\n",
    "\n",
    "reviews = [\n",
    "    \"The staff was friendly but the wait time was terrible.\",\n",
    "    \"Great product quality, but the checkout process was slow.\",\n",
    "    \"Amazing experience overall!\"\n",
    "]\n",
    "\n",
    "themes = [\"staff\", \"wait time\", \"product quality\", \"checkout\"]\n",
    "\n",
    "result = await local_client.analyze_sentiment(reviews, themes, response_model=SentimentAnalysis)\n",
    "print(f\"Sentiment analysis JSON: {type(result)}\\n\", result)\n",
    "# 9m 13.1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5a0f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c723b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00465518",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from config import config\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "import base64\n",
    "import logging\n",
    "import json\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class AzureOpenAIClient:\n",
    "    def __init__(self):\n",
    "        # Initialize only if Azure configuration is available\n",
    "        if not config.is_azure_configured() or config.AZURE_OPENAI_API_KEY.startswith(\"mock\"):\n",
    "            logger.warning(\"Azure OpenAI is in mock mode or not configured.\")\n",
    "            self.llm = None\n",
    "        else:\n",
    "            try:\n",
    "                self.llm = ChatOpenAI(\n",
    "                base_url=\"http://127.0.0.1:8080\",\n",
    "                model=\"\",\n",
    "                api_key=\"NA\"\n",
    "                )\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to initialize langchain-openai ChatOpenAI client: {str(e)}\")\n",
    "                self.llm = None\n",
    "\n",
    "    def is_configured(self) -> bool:\n",
    "        return self.llm is not None\n",
    "\n",
    "    async def chat_completion(\n",
    "        self,\n",
    "        messages: List[Dict[str, Any]],\n",
    "        deployment: Optional[str] = None,\n",
    "        temperature: float = 0.7,\n",
    "        max_tokens: int = 2000,\n",
    "    ) -> str:\n",
    "        \"\"\"General chat completion for text generation\"\"\"\n",
    "        if not self.is_configured():\n",
    "            return \"Azure OpenAI is not configured. Please set API credentials.\"\n",
    "\n",
    "        try:\n",
    "            # Convert OpenAI-style messages to LangChain messages\n",
    "            formatted_messages = []\n",
    "            for msg in messages:\n",
    "                role = msg.get(\"role\")\n",
    "                content = msg.get(\"content\")\n",
    "                if role == \"system\":\n",
    "                    formatted_messages.append(SystemMessage(content=content))\n",
    "                elif role == \"assistant\":\n",
    "                    formatted_messages.append(AIMessage(content=content))\n",
    "                else:\n",
    "                    formatted_messages.append(HumanMessage(content=content))\n",
    "\n",
    "            llm = ChatOpenAI(\n",
    "                base_url=\"http://127.0.0.1:8080\",\n",
    "                model=\"\",\n",
    "                api_key=\"NA\",\n",
    "                temperature=temperature,\n",
    "                max_tokens=max_tokens,\n",
    "            )\n",
    "\n",
    "            response = await llm.ainvoke(formatted_messages)\n",
    "            return response.content\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Azure OpenAI API error: {str(e)}\")\n",
    "            raise Exception(f\"Failed to get completion: {str(e)}\")\n",
    "\n",
    "    async def analyze_image(self, image_path: str, prompt: str, deployment: Optional[str] = None) -> str:\n",
    "        \"\"\"Analyze image using GPT-4 Vision\"\"\"\n",
    "        if not self.is_configured():\n",
    "            return \"Azure OpenAI is not configured. Please set API credentials.\"\n",
    "\n",
    "        try:\n",
    "            with open(image_path, 'rb') as image_file:\n",
    "                image_data = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "            image_message = {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"}, \"detail\": \"low\"},\n",
    "                ],\n",
    "            }\n",
    "\n",
    "            response = await self.chat_completion(\n",
    "                messages=[image_message],\n",
    "                deployment=deployment,\n",
    "                temperature=0.5,\n",
    "                max_tokens=2000,\n",
    "            )\n",
    "\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Image analysis error: {str(e)}\")\n",
    "            raise Exception(f\"Failed to analyze image: {str(e)}\")\n",
    "\n",
    "    async def analyze_sentiment(self, reviews: List[str], themes: List[str]) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze sentiment across multiple themes\"\"\"\n",
    "        prompt = f\"\"\"Analyze the following customer reviews for a retail store and provide sentiment scores for each theme.\n",
    "\n",
    "Themes to analyze: {', '.join(themes)}\n",
    "\n",
    "Reviews:\n",
    "{chr(10).join([f'{i+1}. {review}' for i, review in enumerate(reviews)])}\n",
    "\n",
    "For each theme, provide:\n",
    "1. Sentiment score from -1 (very negative) to 1 (very positive)\n",
    "2. Brief explanation\n",
    "3. Sample quotes from reviews\n",
    "\n",
    "Respond in JSON format:\n",
    "{{\n",
    "    \"themes\": [\n",
    "        {{\n",
    "            \"theme\": \"theme_name\",\n",
    "            \"score\": 0.5,\n",
    "            \"explanation\": \"brief explanation\",\n",
    "            \"sample_quotes\": [\"quote1\", \"quote2\"]\n",
    "        }}\n",
    "    ],\n",
    "    \"overall_sentiment\": 0.3\n",
    "}}\"\"\"\n",
    "\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        response = await self.chat_completion(messages, temperature=0.3)\n",
    "\n",
    "        try:\n",
    "            return json.loads(response.replace(\"```\", \"\").replace(\"json\", \"\"))\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Azure: Sentiment analysis error: {str(e)}, response: {str(response)}\")\n",
    "            return {\"themes\": [], \"overall_sentiment\": 0}\n",
    "\n",
    "\n",
    "# Global instance\n",
    "azure_client = AzureOpenAIClient()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a122c453",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather like in Paris?\"}\n",
    "]\n",
    "result = await azure_client.chat_completion(messages)\n",
    "print(\"Chat Completion:\", result)\n",
    "\n",
    "\n",
    "image_path = \"C:\\\\Users\\\\rahul_thatikonda\\\\Desktop\\\\AIStoreAssistant\\\\Inputs\\\\Images\\\\Store 2\\\\Store2-09-06-2024.png\"\n",
    "prompt = f\"\"\"Analyze this retail store image and provide scores (0-100) for the following metrics:\n",
    "\n",
    "        1. Cleanliness: How clean and tidy is the store?\n",
    "        2. Empty Shelves: Are there empty or poorly stocked shelves? (100 = fully stocked, 0 = many empty)\n",
    "        3. Queue Length: How long are the checkout queues?, this field is only relevant situations like checkout (100 = no queue, 0 = very long queues)\n",
    "        4. Staff Presence: Is staff visible and available? (100 = good staffing, 0 = no staff visible)\n",
    "        5. Store Organization: How well organized is the store layout?\n",
    "        6. Immediate Issues: This is optional field, only provide value if it's relevant to situation ([\"Restock aisle 1\"], [\"\"])\n",
    "\n",
    "        For each metric, provide:\n",
    "        - score (0-100)\n",
    "        - details (brief description - ignore if it's optional or not relevant to situation)\n",
    "\n",
    "        Also identify any issues that need immediate attention (spills, hazards, etc.)\n",
    "\n",
    "        Respond in JSON format:\n",
    "        {{\n",
    "            \"cleanliness\": {{\"score\": 85, \"details\": \"Store is generally clean\"}},\n",
    "            \"empty_shelves\": {{\"score\": 70, \"details\": \"Some gaps in produce section\"}},\n",
    "            \"queue_length\": {{\"score\": 60, \"details\": \"Moderate queues at 2 checkouts\"}},\n",
    "            \"staff_presence\": {{\"score\": 80, \"details\": \"Staff visible in multiple areas\"}},\n",
    "            \"store_organization\": {{\"score\": 90, \"details\": \"Well organized layout\"}},\n",
    "            \"immediate_issues\": [\"Minor spill in aisle 3\"]\n",
    "        }}\"\"\"\n",
    "result = await azure_client.analyze_image(image_path, prompt)\n",
    "print(\"Image Analysis:\", result)\n",
    "\n",
    "\n",
    "reviews = [\n",
    "    \"The store was clean and the staff was very friendly.\",\n",
    "    \"The product selection could have been better.\",\n",
    "    \"Checkout was fast, but parking was difficult.\"\n",
    "]\n",
    "themes = [\"cleanliness\", \"staff friendliness\", \"product selection\", \"checkout\", \"parking\"]\n",
    "result = await azure_client.analyze_sentiment(reviews, themes)\n",
    "print(\"Sentiment Analysis:\", result)\n",
    "# 5m 46.0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dae59e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
